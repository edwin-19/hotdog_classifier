{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amino-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from efficientnet.tfkeras import EfficientNetB3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    "import seaborn as sns\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "looking-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "learning_rate = 1e-4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-walnut",
   "metadata": {},
   "source": [
    "# Model building\n",
    "- Lets build a model similar to how a pytorch model is trained\n",
    "- Via the subclass api, we can make it similar to a nn.Module api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "portuguese-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HotDogClassifier(tf.keras.Model):\n",
    "    def __init__(self, input_shape=(224, 224, 3), num_classes=2):\n",
    "        super(HotDogClassifier, self).__init__()\n",
    "        self.base_model = EfficientNetB3(input_shape=input_shape, include_top=False)\n",
    "#         self.base_model = tf.keras.applications.EfficientNetB3(input_shape=input_shape, include_top=False)\n",
    "        self.base_model.trainable = False\n",
    "        \n",
    "        self.flatten = tf.keras.layers.GlobalAveragePooling2D()\n",
    "        self.fc_1 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.fc_output = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc_1(x)\n",
    "        x = self.fc_output(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "resident-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"hot_dog_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnet-b3 (Functional) (None, 7, 7, 1536)        10783528  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  393472    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  514       \n",
      "=================================================================\n",
      "Total params: 11,177,514\n",
      "Trainable params: 393,986\n",
      "Non-trainable params: 10,783,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = HotDogClassifier()\n",
    "model.build((None, 224, 224, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-sacramento",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "- Lets load our data into a dataset api, similar to how pytorch does\n",
    "- But no dataloader is present for tensorflow, but you can load batch via dataset, instead of dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smooth-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('data/**/*.jpg', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "medieval-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"labels\": [],\n",
    "    \"images_path\": []\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    'not_hot_dog': 0,\n",
    "    'hot_dog': 1\n",
    "}\n",
    "\n",
    "for image in images:\n",
    "    data['images_path'].append(image)\n",
    "    data['labels'].append(\n",
    "        labels[os.path.basename(os.path.dirname(image))]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "individual-reference",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, train_labels, validation_labels = train_test_split(\n",
    "    data['images_path'], data['labels'], \n",
    "    test_size=0.3, stratify=data['labels'], random_state=2021\n",
    ")\n",
    "\n",
    "validation_data, test_data, validation_labels, test_labels = train_test_split(\n",
    "    validation_data, validation_labels,\n",
    "    test_size=0.5, stratify=validation_labels, random_state=2021\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "active-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(images_path, labels):\n",
    "    image = tf.io.decode_jpeg(tf.io.read_file(images_path), channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = image / 255.\n",
    "    \n",
    "    return image, tf.one_hot(labels, depth=2)\n",
    "    \n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels))\\\n",
    "            .shuffle(buffer_size=1024)\\\n",
    "            .map(convert_data)\\\n",
    "            .batch(batch_size)\\\n",
    "            .cache()\\\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_data, validation_labels))\\\n",
    "            .map(convert_data)\\\n",
    "            .batch(batch_size)\\\n",
    "            .cache()\\\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels))\\\n",
    "            .map(convert_data)\\\n",
    "            .batch(batch_size)\\\n",
    "            .cache()\\\n",
    "            .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-diagnosis",
   "metadata": {},
   "source": [
    "# Train with custom loop\n",
    "- To do this we need to use the gradient tape api\n",
    "- Before that declare our loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "excited-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "train_metrics = tf.keras.metrics.Accuracy()\n",
    "val_metrics = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "innovative-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def training_step(x_batch_train, y_batch_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x_batch_train, training=True)\n",
    "        loss_value = loss(y_batch_train, logits)\n",
    "\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_metrics.update_state(y_batch_train, logits)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def validation_step(x_batch_val, y_batch_val):\n",
    "    logits = model(x_batch_val, training=False)\n",
    "    loss_value = loss(y_batch_val, logits)\n",
    "    \n",
    "    val_metrics.update_state(y_batch_val, logits)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-microwave",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec7dd5e6b1b41aeb70050b2fc3f9864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss (for one batch) at step 0: 0.7989\n",
      "Seen so far: 64 samples\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'validation_loss': []\n",
    "}\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Train data\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        loss_value = training_step(x_batch_train, y_batch_train)\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one batch) at step %d: %.4f\"\n",
    "                % (step, float(loss_value))\n",
    "            )\n",
    "            print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
    "    \n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_acc = train_metrics.result()\n",
    "    history['train_loss'].append(loss_value)\n",
    "    print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
    "    \n",
    "    # Validation data\n",
    "    for x_batch_val, y_batch_val in validation_dataset:\n",
    "        val_loss = validation_step(x_batch_val, y_batch_val)\n",
    "        \n",
    "    val_acc = val_metrics.result()\n",
    "    history['validation_loss'].append(val_loss)\n",
    "    print(\"Validation acc over epoch: %.4f\" % (float(val_acc),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.title('Loss History')\n",
    "plt.plot(history['train_loss'], label='train_loss')\n",
    "plt.plot(history['validation_loss'], label='validation_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-slovakia",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-recovery",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-baker",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "conf_mat = confusion_matrix(test_labels, y_pred)\n",
    "categories = ['Negative', 'Positive']\n",
    "group_names = ['True Neg','False Pos', 'False Neg','True Pos']\n",
    "\n",
    "group_percentage = [\n",
    "    '{0:.2%}'.format(value) for value in conf_mat.ravel() / conf_mat.sum()\n",
    "]\n",
    "\n",
    "cm_labels = [f'{v1}\\n{v2}' for v1, v2 in zip(group_names,group_percentage)]\n",
    "\n",
    "cm_labels = np.array(cm_labels).reshape(2, 2)\n",
    "\n",
    "plt.xlabel(\"Predicted values\", fontdict = {'size':14}, labelpad = 10)\n",
    "plt.ylabel(\"Actual values\"   , fontdict = {'size':14}, labelpad = 10)\n",
    "plt.title (\"Confusion Matrix\", fontdict = {'size':18}, pad = 20)\n",
    "sns.heatmap(\n",
    "    conf_mat, annot=cm_labels, fmt='',\n",
    "    xticklabels=categories, yticklabels=categories\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Roc: {}\\nMCC: {}'.format(\n",
    "    round(roc_auc_score(test_labels, y_pred, average='macro'), 2), \n",
    "    round(matthews_corrcoef(test_labels, y_pred), 2))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-illness",
   "metadata": {},
   "source": [
    "# Visually Inspect\n",
    "- Lets run inference and check manually how does our model perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = {\n",
    "    0: 'not hot dog',\n",
    "    1: 'hot dog'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "row, column, count = 3, 5, 0\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "for test_image in np.random.choice(test_data, size=15):\n",
    "    image = tf.io.decode_jpeg(tf.io.read_file(test_image), channels=3)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    image = image / 255.\n",
    "    image = tf.expand_dims(image, axis=0)\n",
    "    \n",
    "    pred = model(image)\n",
    "    pred = tf.squeeze(pred, axis=0)\n",
    "    pred = pred.numpy()\n",
    "\n",
    "    count += 1\n",
    "    plt.subplot(row, column, count)\n",
    "    plt.title(decoder[pred.argmax()] + ': ' + str(round(pred.max() * 100, 2)) + '%')\n",
    "    plt.imshow(tf.cast(image[0] * 255, tf.uint8))\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
